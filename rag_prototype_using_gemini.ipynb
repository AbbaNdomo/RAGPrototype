{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RAG SYSTEM FOR FINANCIAL DOCUMENTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PIP Installations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following classes will need to be imported from their respsective packages: \n",
    "\n",
    "    - google-genai\n",
    "    - azure-search-docments\n",
    "    - langchain-google-genai\n",
    "    - langchain-chroma\n",
    "\n",
    "Note that either one of chroma or azure-search will be used as a vector data base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%capture\n",
    "#%pip install langchain-core langchain-community langchain-google-genai\n",
    "#%pip install azure-ai-documentintelligence azure-search-documents\n",
    "#%pip install -U langchain-google-genai\n",
    "#%pip install -U langchain-chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up the Environment to use Google's GenAI llm products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyB9hPjhpqM6THjy_qn8Ne214BLL1MZpobQ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing Google's Chat Generative AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-f243ff4f-6c97-4a21-9d97-6c91553f5db0-0', usage_metadata={'input_tokens': 21, 'output_tokens': 6, 'total_tokens': 27})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing Google Gemini Langchain interation\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading  & Chunking documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Defining a method used to loop through a directory and load all documents inside it.**\n",
    "\n",
    "The loading is carried out by an instance of AzureAIDocumentIntelligenceLoader for the following purposes:\n",
    "\n",
    "    - Ablility to analyze tables, images, and text, extracting all information from the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(direc_path, doc_intelligence_endpoint, doc_intelligence_key):\n",
    "    docs = []\n",
    "    for file in os.listdir(direc_path):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            file_path = direc_path + \"/\"+ file\n",
    "            loader = AzureAIDocumentIntelligenceLoader(file_path=file_path, api_endpoint= doc_intelligence_endpoint, api_key=doc_intelligence_key, api_model=\"prebuilt-layout\", mode=\"markdown\", analysis_features= [\"ocrHighResolution\"])\n",
    "            docs += loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a AzureAIDocumentIntelligence resource noting down it's endpoint and api_key.\n",
    "\n",
    "\"OcrHighResolution\" is a Read Optical Character Recognition (OCR) model. It runs at a higher resolution than Azure AI Vision Read and extracts print and handwritten text from PDF documents and scanned images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of docs: 4\n"
     ]
    }
   ],
   "source": [
    "# Loading sample document (invoice)\n",
    "#url_path = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/rest-api/layout.png\"\n",
    "\n",
    "endpoint = \"https://docintelone.cognitiveservices.azure.com/\"\n",
    "key = \"64c61ce74d924ced974b3ee968e50fbe\"\n",
    "\n",
    "analysis_features = [\"ocrHighResolution\"]\n",
    "\n",
    "direc_path = \"/teamspace/studios/this_studio/Shrinked\"\n",
    "docs = load_docs(direc_path, endpoint, key)\n",
    "print(\"Length of docs: {}\".format(len(docs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting**\n",
    "\n",
    "The RecursiveCharacterTextSplitter is used because of its simplicity. It breaks down text into smaller *\"chunks\"* depending on your choice of *\"chunk_size\"* and *\"overlap\"*.\n",
    "\n",
    "For a query based system, it is important to minimize the chunk_size to allow for effective retrieval, however, it is also important to have them as large as possible to minimize storage utilisation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunking using Langchain splitters\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor split in splits: \\n    print(split.page_content)\\n    print(\"----------------------------------------------------------------------------------\")\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for split in splits: \n",
    "    print(split.page_content)\n",
    "    print(\"----------------------------------------------------------------------------------\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Embedding Stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up embeddings\n",
    "\n",
    "model = \"models/embedding-001\"\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VECTOR STORE USING AZURE_SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom langchain_community.vectorstores.azuresearch import AzureSearch\\n\\nvector_store_address: str = \"https://ragsearchone.search.windows.net\"\\nvector_store_password: str = \"oZfKSbPgirnz2DlPhtHA8KQjcJ8UaRKnpANa7UI16EAzSeC0NfRj\"\\n\\nindex_name: str = \"langchain-rag-prototype\"\\nvectorstore: AzureSearch = AzureSearch(\\n    azure_search_endpoint=vector_store_address,\\n    azure_search_key=vector_store_password,\\n    index_name=index_name,\\n    embedding_function=embeddings.embed_query,\\n    additional_search_client_options={\"retry_total\": 4},\\n)\\nretriever = vectorstore.as_retriever(search_type=\"similarity\")\\n\\nvectorstore.add_documents(documents=docs)\\n\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up Azure Search\n",
    "\"\"\"\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "vector_store_address: str = \"https://ragsearchone.search.windows.net\"\n",
    "vector_store_password: str = \"oZfKSbPgirnz2DlPhtHA8KQjcJ8UaRKnpANa7UI16EAzSeC0NfRj\"\n",
    "\n",
    "index_name: str = \"langchain-rag-prototype\"\n",
    "vectorstore: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    "    additional_search_client_options={\"retry_total\": 4},\n",
    ")\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "vectorstore.add_documents(documents=docs)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VECTOR STORE USING CHROMA_DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Chroma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_documents(splits, embeddings)\n\u001b[1;32m      3\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m      5\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39madd_documents(documents\u001b[38;5;241m=\u001b[39mdocs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Chroma' is not defined"
     ]
    }
   ],
   "source": [
    "vectorstore = Chroma.from_documents(splits, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "vectorstore.add_documents(documents=docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VECTOR STORE USING FAISS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrieval-Augmented Generation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprompt = ChatPromptTemplate.from_messages(\\n    [\\n        (\"system\", system_prompt),\\n        (\"human\", \"{input}\"),\\n    ]\\n)\\n\\nquestion_answer_chain = create_stuff_documents_chain(llm, prompt)\\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rag prompt for retrieval\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs): \n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many shares did Uber issue and sell during its IPO? \n",
      " Answer: On May 14, 2019, Uber issued and sold 180 million shares of its common stock during its IPO. The price per share was $45.00.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What was the price per share during Uber’s IPO? \n",
      " Answer: The price per share during Uber’s IPO was $45.00.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How much net proceeds did Uber receive from the IPO? \n",
      " Answer: On May 14, 2019, Uber received approximately $8.0 billion in net proceeds from its initial public offering (IPO). This figure is after deducting $106 million in underwriting discounts and commissions and offering expenses.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How many shares of common stock were converted from the outstanding redeemable convertible preferred stock upon the IPO? \n",
      " Answer: Upon the IPO, all shares of the Company's outstanding redeemable convertible preferred stock automatically converted into 905 million shares of common stock.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What was the tax withholding obligation based on the IPO public offering price? \n",
      " Answer: Based on the IPO public offering price of $45.00 per share, the tax withholding obligation was $1.3 billion. The company issued 76 million shares of common stock, and withheld 29 million shares to meet the tax withholding requirements.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How much did Uber agree to pay for its controlling interest in Cornershop? \n",
      " Answer: Uber agreed to pay up to $459 million for its controlling interest in Cornershop, payable in a combination of cash and Uber common stock.\n",
      "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#questions = \"When does Apple recognize revenue for its products?, How does Apple allocate revenue for arrangements with multiple performance obligations?, What are the three performance obligations identified by Apple for iPhone Mac and iPad sales?, How is revenue allocated to product-related bundled services and unspecified software upgrade rights recognized?, What factors does Apple consider when determining control of third-party products?, How does Apple account for third-party application-related sales through the App Store?\"\n",
    "#questions = \"How much deferred revenue was recognized by Apple in the year 2023?, How much deferred revenue from the previous year was recognized by Apple in the year 2022?, What amount from the year prior to that was recognized as part of Apple's net sales for the year ending on September 26th?, In which region did iPhone sales represent a higher proportion than usual according to Note 13?, As of September 30th, what is the total amount reported for total deferred revenues?, What is Apple's reported amount for total deferred revenues as of December 24th?\"\n",
    "questions = \"How many shares did Uber issue and sell during its IPO?, What was the price per share during Uber’s IPO?, How much net proceeds did Uber receive from the IPO?, How many shares of common stock were converted from the outstanding redeemable convertible preferred stock upon the IPO?, What was the tax withholding obligation based on the IPO public offering price?, How much did Uber agree to pay for its controlling interest in Cornershop?\"\n",
    "\n",
    "list = questions.split(\",\")\n",
    "\n",
    "for num, question in enumerate(list):\n",
    "    response = rag_chain.invoke(question)\n",
    "    #answer = response[\"answer\"]\n",
    "    #print(\"Question: {} \\n Answer: {}\".format(question, answer))\n",
    "    print(\"Question: {} \\n Answer: {}\".format(question, response))\n",
    "    print(\"________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_google_genai/chat_models.py:350: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple's net Products sales as of September 30, 2023 were $298,085 million.\n"
     ]
    }
   ],
   "source": [
    "# Retrieval using Gemini\n",
    "\"\"\"\n",
    "response = rag_chain.invoke({\"input\": \"During Uber's IPO, how many shares of common stock were sold, at what price were they sold, and how much were the net proceeds received?\"})\n",
    "response[\"answer\"]\n",
    "\"\"\"\n",
    "\n",
    "response = rag_chain.invoke(\"As of september 30, 2023, what was  Apple's net Products sales?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In progress: Adding chat history as context to the rag chain so that the chatbot has even more context and chat seems natural."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
